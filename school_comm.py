# -*- coding: utf-8 -*-
"""school_comm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VXXrfA7Hhw9JyjgsZRYl19TMMm1AZvm1
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install python-dotenv

from dotenv import load_dotenv
import os

# load_dotenv('/content/drive/MyDrive/Agentic_Property/OpenAI_Key/.env')
load_dotenv('/content/drive/MyDrive/Agentic_Property/OpenAI_Key/.env', verbose=True)


api_key = os.getenv('OPENAI_API_KEY')

import json

#load messages
messages_path = '/content/drive/MyDrive/Al-Arqam-Project/data/school_comm.json'

with open(messages_path, 'r') as f:
    messages = json.load(f)

from openai import OpenAI
client = OpenAI(api_key=api_key)

def get_embedding(text, model="text-embedding-3-small"):
    response = client.embeddings.create(
        input=[text],
        model=model
    )
    return response.data[0].embedding

# generate embeddings

message_embeddings = []

for msg in messages:
    full_text = f"Subject: {msg['subject']}\n\n{msg['body']}"
    embedding = get_embedding(full_text)
    message_embeddings.append({
        "id": msg["id"],
        "embedding": embedding
    })

# 4. Save Embeddings to a New File

embeddings_path = '/content/drive/MyDrive/Al-Arqam-Project/data/message_embeddings.json'

with open(embeddings_path, 'w') as f:
    json.dump(message_embeddings, f)

# Step 1: Convert User Question to Embedding

#user_question = "What time is the Quran award ceremony for 3rd grade?"


#user_question = "Which teachers put together the Quran ceremony?"

user_question = "When is the coffee chat? is there specific time?"
user_embedding = get_embedding(user_question)

# Step 2: Compare with Stored Message Embeddings (Cosine Similarity)

from scipy.spatial.distance import cosine

def find_most_similar(user_emb, stored_embeddings, top_k=2):
    scored = [
        (entry["id"], 1 - cosine(user_emb, entry["embedding"]))
        for entry in stored_embeddings
    ]
    top_matches = sorted(scored, key=lambda x: x[1], reverse=True)[:top_k]
    return top_matches

top_matches = find_most_similar(user_embedding, message_embeddings)
print(top_matches)

# Step 3: Find Original Message Text for GPT

def get_message_by_id(messages, msg_id):
    for msg in messages:
        if msg["id"] == msg_id:
            return msg
    return None

# Get top 2 matched messages
top_contexts = [get_message_by_id(messages, match[0]) for match in top_matches]

# Step 4: Format Prompt and Ask GPT

def ask_gpt(question, context_messages):
    context_text = "\n\n".join([
        f"Subject: {msg['subject']}\n\n{msg['body']}" for msg in context_messages if msg
    ])

    prompt = f"""
You are a helpful assistant that answers parent questions using school communications.

Context:
{context_text}

Question:
{question}

Answer:
"""

    response = client.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )

    return response.choices[0].message.content.strip()

final_answer = ask_gpt(user_question, top_contexts)
print("GPT Answer:", final_answer)